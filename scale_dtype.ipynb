{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990f176a-891d-48a2-a6e0-9932a6aa6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hqq.core.quantize import (\n",
    "    BaseQuantizeConfig, \n",
    "    HQQLinear\n",
    ")\n",
    "from hqq.models.hf.base import AutoHQQHFModel\n",
    "from lm_eval.models.huggingface import HFLM\n",
    "\n",
    "import gc\n",
    "import lm_eval\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c42f83a-8b74-4111-836d-5cc568784196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(model: torch.nn.Module, group_size: int, scale_dtype: torch.dtype) -> torch.nn.Module:\n",
    "    qconfig = BaseQuantizeConfig(\n",
    "        nbits = 4,\n",
    "        group_size = group_size,\n",
    "        axis = 1,\n",
    "        quant_zero = False,\n",
    "    )\n",
    "\n",
    "    # Use RTN quantization (no HQQ algorithm).\n",
    "    qconfig[\"weight_quant_params\"][\"optimize\"] = False\n",
    "\n",
    "    AutoHQQHFModel.quantize_model(model, quant_config=qconfig, compute_dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "    # Simulate low-precision scale dtypes by round-trip conversion\n",
    "    if scale_dtype != torch.float32:\n",
    "        for linear in filter(lambda m: isinstance(m, HQQLinear), model.modules()):\n",
    "            linear.meta['scale'] = linear.meta['scale'].to(scale_dtype).to(torch.float32)\n",
    "            linear.meta['zero'] = linear.meta['zero'].to(scale_dtype).to(torch.float32)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c5c7e64-305e-4544-a070-09346a5cdddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:47:42,979 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing group_size=None, scale_dtype=None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70618421ef4a45179e3093d68511e284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce939545d584c59822b68556002e9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4541860e4b419c924264904b3a769b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000599c005ae43b8a8f066a7373aca11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820d28fe27f946419a2566266fb3b6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e74afa853134b538b4ef5406c217acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97ce3b70022468faf343a6426d959f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447977c216904ae4adfdb60b72ca3a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/33.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be756c9c692c46829b380dd86d2dfd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6208bf637eb4588afad4b3899d3aded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46500ef301cd4d63af83e546e2282add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:49:29,399 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "2024-06-25:10:49:29,605 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:49:32,604 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:49:32,604 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:49:32,605 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:49:32,605 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:49:32,606 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:49:32,606 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:49:34,276 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:49:34,308 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:49:34,310 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 945.15it/s]\n",
      "2024-06-25:10:49:34,380 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:22<00:00,  2.71it/s]\n",
      "2024-06-25:10:49:59,095 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': None, 'scale_dtype': None, 'word_perplexity': 15.937837625212639}\n",
      "Testing group_size=32, scale_dtype=torch.float32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565f8fc67e0544c98f174152eafc0468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:50:01,329 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 4922.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 154.04it/s]\n",
      "2024-06-25:10:50:02,870 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:50:05,767 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:50:05,768 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:50:05,768 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:50:05,768 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:50:05,769 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:50:05,770 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:50:07,270 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:50:07,290 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:50:07,292 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1184.60it/s]\n",
      "2024-06-25:10:50:07,348 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:50<00:00,  1.23it/s]\n",
      "2024-06-25:10:50:58,949 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 32, 'scale_dtype': torch.float32, 'word_perplexity': 16.60041899416348}\n",
      "Testing group_size=32, scale_dtype=torch.float16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ee96b7edfc46f9ba8f9068fe09bec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:51:01,078 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 4183.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 287.33it/s]\n",
      "2024-06-25:10:51:02,246 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:51:05,119 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:51:05,120 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:51:05,120 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:51:05,121 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:51:05,121 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:51:05,121 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:51:06,735 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:51:06,755 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:51:06,758 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1164.60it/s]\n",
      "2024-06-25:10:51:06,814 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:49<00:00,  1.24it/s]\n",
      "2024-06-25:10:51:57,844 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 32, 'scale_dtype': torch.float16, 'word_perplexity': 16.598585300104553}\n",
      "Testing group_size=32, scale_dtype=torch.bfloat16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f290e57f3bbd476395567f9ab9700f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:51:59,988 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 5246.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 283.95it/s]\n",
      "2024-06-25:10:52:01,149 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:52:04,015 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:52:04,015 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:52:04,016 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:52:04,017 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:52:04,017 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:52:04,017 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:52:05,547 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:52:05,566 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:52:05,568 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1165.02it/s]\n",
      "2024-06-25:10:52:05,625 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:49<00:00,  1.24it/s]\n",
      "2024-06-25:10:52:56,564 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 32, 'scale_dtype': torch.bfloat16, 'word_perplexity': 16.614811228653455}\n",
      "Testing group_size=64, scale_dtype=torch.float32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac0142251e84f61bc51561ed92c9263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:52:58,660 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 4957.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 323.39it/s]\n",
      "2024-06-25:10:52:59,742 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:53:02,600 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:53:02,601 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:53:02,601 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:53:02,602 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:53:02,602 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:53:02,602 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:53:04,282 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:53:04,302 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:53:04,304 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1153.06it/s]\n",
      "2024-06-25:10:53:04,361 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:50<00:00,  1.23it/s]\n",
      "2024-06-25:10:53:55,673 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 64, 'scale_dtype': torch.float32, 'word_perplexity': 18.16199412991154}\n",
      "Testing group_size=64, scale_dtype=torch.float16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce391b8886f475cb8fb410dc31cb47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:53:57,817 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 5134.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 311.61it/s]\n",
      "2024-06-25:10:53:58,930 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:54:01,793 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:54:01,794 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:54:01,794 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:54:01,795 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:54:01,795 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:54:01,796 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:54:03,403 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:54:03,423 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:54:03,425 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1174.46it/s]\n",
      "2024-06-25:10:54:03,481 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:49<00:00,  1.24it/s]\n",
      "2024-06-25:10:54:54,408 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 64, 'scale_dtype': torch.float16, 'word_perplexity': 18.15976221447611}\n",
      "Testing group_size=64, scale_dtype=torch.bfloat16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3a6c18f5974d4481f826a78ced98f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:54:56,533 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 2590.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 308.30it/s]\n",
      "2024-06-25:10:54:57,638 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:55:00,495 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:55:00,496 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:55:00,496 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:55:00,496 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:55:00,497 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:55:00,497 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:55:02,225 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:55:02,244 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:55:02,246 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1164.69it/s]\n",
      "2024-06-25:10:55:02,303 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:50<00:00,  1.23it/s]\n",
      "2024-06-25:10:55:53,527 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 64, 'scale_dtype': torch.bfloat16, 'word_perplexity': 18.143062491216615}\n",
      "Testing group_size=128, scale_dtype=torch.float32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39f7342c4884184b8d16b879285035c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:55:55,628 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 5092.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 396.54it/s]\n",
      "2024-06-25:10:55:56,621 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:55:59,503 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:55:59,504 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:55:59,504 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:55:59,504 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:55:59,505 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:55:59,505 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:56:01,158 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:56:01,178 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:56:01,180 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1164.21it/s]\n",
      "2024-06-25:10:56:01,236 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:50<00:00,  1.23it/s]\n",
      "2024-06-25:10:56:52,776 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 128, 'scale_dtype': torch.float32, 'word_perplexity': 18.83537783888739}\n",
      "Testing group_size=128, scale_dtype=torch.float16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451e77841f35442eb3903b4670324eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:56:54,907 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 5139.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 358.13it/s]\n",
      "2024-06-25:10:56:55,938 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:56:58,804 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:56:58,805 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:56:58,805 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:56:58,806 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:56:58,806 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:56:58,806 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:57:00,452 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:57:00,473 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:57:00,475 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1136.39it/s]\n",
      "2024-06-25:10:57:00,533 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:50<00:00,  1.24it/s]\n",
      "2024-06-25:10:57:51,585 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 128, 'scale_dtype': torch.float16, 'word_perplexity': 18.833921791419556}\n",
      "Testing group_size=128, scale_dtype=torch.bfloat16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6440db9dcaa47a491deac5fb97eaf28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:57:53,622 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 5721.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 408.69it/s]\n",
      "2024-06-25:10:57:54,616 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:57:57,505 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:57:57,506 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:57:57,506 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:57:57,507 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:57:57,507 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:57:57,507 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:57:59,038 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:57:59,057 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:57:59,059 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1178.81it/s]\n",
      "2024-06-25:10:57:59,115 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:49<00:00,  1.25it/s]\n",
      "2024-06-25:10:58:49,929 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 128, 'scale_dtype': torch.bfloat16, 'word_perplexity': 18.84277287923962}\n",
      "Testing group_size=256, scale_dtype=torch.float32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cae5e5f9b345138306473e8765bcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:58:51,972 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 5860.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 404.56it/s]\n",
      "2024-06-25:10:58:52,955 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:58:55,851 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:58:55,851 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:58:55,852 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:58:55,852 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:58:55,853 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:58:55,853 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:58:57,503 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:58:57,524 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:58:57,526 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1148.90it/s]\n",
      "2024-06-25:10:58:57,583 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:50<00:00,  1.24it/s]\n",
      "2024-06-25:10:59:48,687 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 256, 'scale_dtype': torch.float32, 'word_perplexity': 19.852184376540393}\n",
      "Testing group_size=256, scale_dtype=torch.float16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a308c6266c4400a6c4470a21b0832f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:10:59:50,878 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 5095.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 376.02it/s]\n",
      "2024-06-25:10:59:51,927 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:10:59:54,807 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:59:54,808 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:59:54,808 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:10:59:54,809 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:10:59:54,809 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:10:59:54,809 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:59:56,372 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:10:59:56,393 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:10:59:56,395 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1133.89it/s]\n",
      "2024-06-25:10:59:56,453 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:50<00:00,  1.24it/s]\n",
      "2024-06-25:11:00:47,505 INFO     [huggingface.py:162] Using device 'cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 256, 'scale_dtype': torch.float16, 'word_perplexity': 19.848994232070204}\n",
      "Testing group_size=256, scale_dtype=torch.bfloat16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregory/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874787aab54147faa793373e14e27ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25:11:00:49,586 INFO     [huggingface.py:273] Model type is 'gemma', a BOS token will be used as Gemma underperforms without it.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:00<00:00, 5429.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 399.10it/s]\n",
      "2024-06-25:11:00:50,593 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-06-25:11:00:53,504 WARNING  [task.py:763] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:11:00:53,504 WARNING  [task.py:775] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:11:00:53,505 WARNING  [task.py:763] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity\n",
      "2024-06-25:11:00:53,505 WARNING  [task.py:775] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "2024-06-25:11:00:53,506 WARNING  [task.py:763] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte\n",
      "2024-06-25:11:00:53,506 WARNING  [task.py:775] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:11:00:54,994 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.\n",
      "2024-06-25:11:00:55,015 WARNING  [evaluator.py:222] Overwriting default num_fewshot of wikitext from None to 0\n",
      "2024-06-25:11:00:55,017 INFO     [task.py:395] Building contexts for wikitext on rank 0...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 1174.04it/s]\n",
      "2024-06-25:11:00:55,073 INFO     [evaluator.py:362] Running loglikelihood_rolling requests\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:49<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_size': 256, 'scale_dtype': torch.bfloat16, 'word_perplexity': 19.871647188905396}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_size</th>\n",
       "      <th>scale_dtype</th>\n",
       "      <th>word_perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>15.937838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>16.600419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>16.598585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>16.614811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>18.161994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>18.159762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>18.143062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>18.835378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>18.833922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>18.842773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>19.852184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>19.848994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>256.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>19.871647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group_size     scale_dtype  word_perplexity\n",
       "0          NaN            None        15.937838\n",
       "1         32.0   torch.float32        16.600419\n",
       "2         32.0   torch.float16        16.598585\n",
       "3         32.0  torch.bfloat16        16.614811\n",
       "4         64.0   torch.float32        18.161994\n",
       "5         64.0   torch.float16        18.159762\n",
       "6         64.0  torch.bfloat16        18.143062\n",
       "7        128.0   torch.float32        18.835378\n",
       "8        128.0   torch.float16        18.833922\n",
       "9        128.0  torch.bfloat16        18.842773\n",
       "10       256.0   torch.float32        19.852184\n",
       "11       256.0   torch.float16        19.848994\n",
       "12       256.0  torch.bfloat16        19.871647"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_sizes = [None, 32, 64, 128, 256]\n",
    "scale_dtypes = [torch.float32, torch.float16, torch.bfloat16]\n",
    "\n",
    "result_rows = []\n",
    "\n",
    "for group_size in group_sizes:\n",
    "    for scale_dtype in scale_dtypes if group_size is not None else [None]:\n",
    "        print(f\"Testing group_size={group_size}, scale_dtype={scale_dtype}...\")\n",
    "        \n",
    "        hflm = HFLM(\n",
    "            #pretrained = \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "            pretrained = \"google/gemma-2b\",\n",
    "            device = \"cuda\",\n",
    "            max_length = 2048,\n",
    "        )\n",
    "\n",
    "        if group_size is not None and scale_dtype is not None:\n",
    "            quantize(hflm.model, group_size = group_size, scale_dtype = scale_dtype)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        results = lm_eval.simple_evaluate(\n",
    "            model = hflm,\n",
    "            tasks = [\"wikitext\"],\n",
    "            num_fewshot = 0,\n",
    "        )['results']\n",
    "        \n",
    "        del hflm\n",
    "        \n",
    "        result_rows.append({\n",
    "            \"group_size\": group_size,\n",
    "            \"scale_dtype\": scale_dtype,\n",
    "            \"word_perplexity\": results['wikitext']['word_perplexity,none']\n",
    "        })\n",
    "\n",
    "        print(result_rows[-1])\n",
    "\n",
    "result_df = pd.DataFrame.from_records(result_rows)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedd5eed-4ea0-4102-89d6-99477c6da525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">word_perplexity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_size</th>\n",
       "      <th>32.0</th>\n",
       "      <th>64.0</th>\n",
       "      <th>128.0</th>\n",
       "      <th>256.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_dtype</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>torch.float32</th>\n",
       "      <td>16.600419</td>\n",
       "      <td>18.161994</td>\n",
       "      <td>18.835378</td>\n",
       "      <td>19.852184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torch.float16</th>\n",
       "      <td>16.598585</td>\n",
       "      <td>18.159762</td>\n",
       "      <td>18.833922</td>\n",
       "      <td>19.848994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torch.bfloat16</th>\n",
       "      <td>16.614811</td>\n",
       "      <td>18.143062</td>\n",
       "      <td>18.842773</td>\n",
       "      <td>19.871647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_perplexity                                 \n",
       "group_size               32.0       64.0       128.0      256.0\n",
       "scale_dtype                                                    \n",
       "torch.float32        16.600419  18.161994  18.835378  19.852184\n",
       "torch.float16        16.598585  18.159762  18.833922  19.848994\n",
       "torch.bfloat16       16.614811  18.143062  18.842773  19.871647"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame.from_records(result_rows)\n",
    "result_df.pivot_table(index='scale_dtype', columns='group_size', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423d4fb8-7a73-4fa2-924c-aea6e05eeae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_size</th>\n",
       "      <th>scale_dtype</th>\n",
       "      <th>word_perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>15.937838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>16.600419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>16.598585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>16.614811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>18.161994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>18.159762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>18.143062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>18.835378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>18.833922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>18.842773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>19.852184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>19.848994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>256.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>19.871647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group_size     scale_dtype  word_perplexity\n",
       "0          NaN            None        15.937838\n",
       "1         32.0   torch.float32        16.600419\n",
       "2         32.0   torch.float16        16.598585\n",
       "3         32.0  torch.bfloat16        16.614811\n",
       "4         64.0   torch.float32        18.161994\n",
       "5         64.0   torch.float16        18.159762\n",
       "6         64.0  torch.bfloat16        18.143062\n",
       "7        128.0   torch.float32        18.835378\n",
       "8        128.0   torch.float16        18.833922\n",
       "9        128.0  torch.bfloat16        18.842773\n",
       "10       256.0   torch.float32        19.852184\n",
       "11       256.0   torch.float16        19.848994\n",
       "12       256.0  torch.bfloat16        19.871647"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
