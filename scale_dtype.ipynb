{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990f176a-891d-48a2-a6e0-9932a6aa6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hqq.core.quantize import (\n",
    "    BaseQuantizeConfig, \n",
    "    HQQLinear\n",
    ")\n",
    "from hqq.models.hf.base import AutoHQQHFModel\n",
    "from lm_eval.models.huggingface import HFLM\n",
    "\n",
    "import gc\n",
    "import lm_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c42f83a-8b74-4111-836d-5cc568784196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(model: torch.nn.Module, group_size: int, scale_dtype: torch.dtype) -> torch.nn.Module:\n",
    "    qconfig = BaseQuantizeConfig(\n",
    "        nbits = 4,\n",
    "        group_size = group_size,\n",
    "        axis = 1,\n",
    "        quant_zero = False,\n",
    "    )\n",
    "\n",
    "    # Use RTN quantization (no HQQ algorithm).\n",
    "    qconfig[\"weight_quant_params\"][\"optimize\"] = False\n",
    "\n",
    "    AutoHQQHFModel.quantize_model(model, quant_config=qconfig, compute_dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "    # Simulate low-precision scale dtypes by round-trip conversion\n",
    "    if scale_dtype != torch.float32:\n",
    "        for linear in filter(lambda m: isinstance(m, HQQLinear), model.modules()):\n",
    "            linear.meta['scale'] = linear.meta['scale'].to(scale_dtype).to(torch.float32)\n",
    "            linear.meta['zero'] = linear.meta['zero'].to(scale_dtype).to(torch.float32)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c7e64-305e-4544-a070-09346a5cdddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#group_sizes = [None, 32, 64, 128, 256]\n",
    "group_sizes = [32]\n",
    "scale_dtypes = [torch.float32] #, torch.float16, torch.bfloat16]\n",
    "\n",
    "result_rows = []\n",
    "\n",
    "for group_size in group_sizes:\n",
    "    for scale_dtype in scale_dtypes if group_size is not None else [None]:\n",
    "        print(f\"Testing group_size={group_size}, scale_dtype={scale_dtype}...\")\n",
    "        \n",
    "        hflm = HFLM(\n",
    "            #pretrained = \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "            pretrained = \"google/gemma-2b\",\n",
    "            device = \"cuda\",\n",
    "            max_length = 2048,\n",
    "        )\n",
    "\n",
    "        if group_size is not None and scale_dtype is not None:\n",
    "            quantize(hflm.model, group_size = group_size, scale_dtype = scale_dtype)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        all_scales = torch.concat([linear.meta['scale'].flatten() for linear in filter(lambda m: isinstance(m, HQQLinear), hflm.model.modules())])\n",
    "        counts, bins = np.histogram(all_scales.cpu())\n",
    "        plt.stairs(counts, bins)\n",
    "        plt.show()\n",
    "\n",
    "        print(pd.DataFrame([all_scales.cpu()]).describe())\n",
    "        \n",
    "        results = lm_eval.simple_evaluate(\n",
    "            model = hflm,\n",
    "            tasks = [\"wikitext\"],\n",
    "            num_fewshot = 0,\n",
    "        )['results']\n",
    "        \n",
    "        del hflm\n",
    "        \n",
    "        result_rows.append({\n",
    "            \"group_size\": group_size,\n",
    "            \"scale_dtype\": scale_dtype,\n",
    "            \"word_perplexity\": results['wikitext']['word_perplexity,none']\n",
    "        })\n",
    "\n",
    "        print(result_rows[-1])\n",
    "\n",
    "result_df = pd.DataFrame.from_records(result_rows)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedd5eed-4ea0-4102-89d6-99477c6da525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">word_perplexity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_size</th>\n",
       "      <th>32.0</th>\n",
       "      <th>64.0</th>\n",
       "      <th>128.0</th>\n",
       "      <th>256.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_dtype</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>torch.float32</th>\n",
       "      <td>16.600419</td>\n",
       "      <td>18.161994</td>\n",
       "      <td>18.835378</td>\n",
       "      <td>19.852184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torch.float16</th>\n",
       "      <td>16.598585</td>\n",
       "      <td>18.159762</td>\n",
       "      <td>18.833922</td>\n",
       "      <td>19.848994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torch.bfloat16</th>\n",
       "      <td>16.614811</td>\n",
       "      <td>18.143062</td>\n",
       "      <td>18.842773</td>\n",
       "      <td>19.871647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_perplexity                                 \n",
       "group_size               32.0       64.0       128.0      256.0\n",
       "scale_dtype                                                    \n",
       "torch.float32        16.600419  18.161994  18.835378  19.852184\n",
       "torch.float16        16.598585  18.159762  18.833922  19.848994\n",
       "torch.bfloat16       16.614811  18.143062  18.842773  19.871647"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame.from_records(result_rows)\n",
    "result_df.pivot_table(index='scale_dtype', columns='group_size', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423d4fb8-7a73-4fa2-924c-aea6e05eeae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_size</th>\n",
       "      <th>scale_dtype</th>\n",
       "      <th>word_perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>15.937838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>16.600419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>16.598585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>16.614811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>18.161994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>18.159762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>18.143062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>18.835378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>18.833922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>128.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>18.842773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256.0</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>19.852184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256.0</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>19.848994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>256.0</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>19.871647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group_size     scale_dtype  word_perplexity\n",
       "0          NaN            None        15.937838\n",
       "1         32.0   torch.float32        16.600419\n",
       "2         32.0   torch.float16        16.598585\n",
       "3         32.0  torch.bfloat16        16.614811\n",
       "4         64.0   torch.float32        18.161994\n",
       "5         64.0   torch.float16        18.159762\n",
       "6         64.0  torch.bfloat16        18.143062\n",
       "7        128.0   torch.float32        18.835378\n",
       "8        128.0   torch.float16        18.833922\n",
       "9        128.0  torch.bfloat16        18.842773\n",
       "10       256.0   torch.float32        19.852184\n",
       "11       256.0   torch.float16        19.848994\n",
       "12       256.0  torch.bfloat16        19.871647"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
